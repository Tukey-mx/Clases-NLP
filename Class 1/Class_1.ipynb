{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "535800d9",
   "metadata": {},
   "source": [
    "# Introducci√≥n a NLP\n",
    "``` Clase 1 ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e087f59",
   "metadata": {},
   "source": [
    "## ¬øQu√© es NLP?\n",
    "\n",
    "El Procesamiento de Lenguaje Natural es la combinaci√≥n de tres √°reas del conocimiento: **CS, ling√º√≠stica, IA**. \n",
    "\n",
    "Su objetivo principal es lograr que las **computadoras puedan entender el lenguaje humano** con el fin de realizar tareas como \\\n",
    "*auto-completado, Q&A, asistentes personales, etc*.\n",
    "\n",
    "Es una de las √°reas m√°s complicadas de la IA, ya que a diferencia de los datos num√©ricos donde de premisa podemos decir que \\\n",
    "√∫nicamente se puede tener un resultado correcto, NLP trabaja con algo muy ambiguo y poco determinista, **el lenguaje**. \n",
    "\n",
    "La interpretaci√≥n del lenguaje depende de muchos factores, por ejemplo, del tono, de la ubicaci√≥n en donde se tiene la pl√°tica, \\\n",
    "la edad de las personas, el contexto en el que se encuentran, etc.\n",
    "\n",
    "1. ¬øMe puedes prestar un borrador?\n",
    "2. Esto se puso color de hormiga\n",
    "3. Efe (???????????)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85caa2ac",
   "metadata": {},
   "source": [
    "![Challenges NLP](Challenges_NLP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70abbed8",
   "metadata": {},
   "source": [
    "## Fases del Procesamiento del lenguaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca43e1a",
   "metadata": {},
   "source": [
    "Con el objetivo de poder tener un mejor entendimiento del lenguaje, los humanos \\\n",
    "dividimos nuestro razonamiento en **5 diferentes fases**\n",
    "\n",
    "1. An√°lisis L√©xico\n",
    "2. An√°lisis Sint√°ctico\n",
    "3. An√°lisis Sem√°ntico\n",
    "4. Integraci√≥n de discurso\n",
    "5. An√°lisis Pragm√°tico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4792e8b",
   "metadata": {},
   "source": [
    "### üü£ An√°lisis L√©xico\n",
    "\n",
    "En esta fase **nos enfocamos en entender la estructura interna de las palabras y c√≥mo se representan como unidades del lenguaje**.\n",
    "\n",
    "El an√°lisis l√©xico identifica:\n",
    "- **Unidades l√©xicas** (*tokens*) como palabras, ra√≠ces, sufijos, afijos, etc\n",
    "- **Categor√≠as gramaticales**: sustantivos, verbos, adjetivos, etc.\n",
    "- **Variaciones de una misma palabra**: jugar, juega, jugando\n",
    "\n",
    "Este paso sienta las bases para poder trabajar con el lenguaje desde un punto de vista m√°s estructurado y formal.\n",
    "\n",
    "üîç *Ejemplo*\n",
    "- En la oraci√≥n *\"Ella juega f√∫tbol\"*, podemos identificar:\n",
    "  - `\"juega\"` como una forma del verbo `\"jugar\"` (ra√≠z)\n",
    "  - su categor√≠a: verbo, en tiempo presente\n",
    "- La palabra `\"r√°pidamente\"` se puede dividir en:\n",
    "  - ra√≠z: `\"r√°pid\"`\n",
    "  - sufijo: `-amente` (que indica adverbio de modo)\n",
    "\n",
    "\n",
    "Computacionalmente hablando, esta fase se traduce en tareas como **tokenizaci√≥n**, **lemmatizaci√≥n**, y **POS tagging**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa7bc7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fe12ff",
   "metadata": {},
   "source": [
    "### üü† An√°lisis Sint√°ctico\n",
    "\n",
    "En esta fase **nos enfocamos en la estructura gramatical de las oraciones**, es decir, c√≥mo se combinan las palabras para formar frases con sentido seg√∫n las reglas del idioma.\n",
    "\n",
    "Se identifican:\n",
    "- Las **relaciones entre palabras** (sujeto, verbo, objeto, modificadores, etc.)\n",
    "- La **jerarqu√≠a** y **estructura** de la oraci√≥n (usualmente representada como un √°rbol sint√°ctico)\n",
    "\n",
    "üîç *Ejemplo*\n",
    "- En la oraci√≥n *\"El gato duerme en la silla\"*:\n",
    "  - `\"El gato\"` es el sujeto\n",
    "  - `\"duerme\"` es el verbo principal\n",
    "  - `\"en la silla\"` es un complemento de lugar (modificador)\n",
    "\n",
    "Computacionalmente hablando, esta fase se traduce en tareas como **parsing**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3a9f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909a3ce",
   "metadata": {},
   "source": [
    "### üü° An√°lisis Sem√°ntico\n",
    "\n",
    "Aqu√≠ **nos interesa el significado literal de las palabras y oraciones**. Es decir, no solo que una oraci√≥n est√© bien formada, sino que lo que diga tenga sentido.\n",
    "\n",
    "Esta fase busca:\n",
    "- Interpretar **el significado de cada palabra** dentro de su contexto\n",
    "- Resolver **ambig√ºedades sem√°nticas** (una palabra puede tener varios significados)\n",
    "\n",
    "üîç *Ejemplo*\n",
    "- En *\"La computadora tom√≥ caf√©\"*, la oraci√≥n es sint√°cticamente v√°lida, pero sem√°nticamente incoherente (¬øuna computadora puede tomar caf√©?).\n",
    "- La palabra *\"banco\"* puede referirse a una instituci√≥n financiera o a un asiento, dependiendo del contexto.\n",
    "\n",
    "Computacionalmente hablando, esta fase se relaciona con **embeddings sem√°nticos**, **resoluci√≥n de ambig√ºedad l√©xica** y **modelos de lenguaje**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d66c1eb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364dc521",
   "metadata": {},
   "source": [
    "### üîµ Integraci√≥n de Discurso\n",
    "\n",
    "Esta fase analiza **c√≥mo se relacionan varias oraciones dentro de un mismo texto**, buscando coherencia y continuidad.\n",
    "\n",
    "El objetivo es:\n",
    "- Mantener la **conexi√≥n l√≥gica** entre ideas\n",
    "- Resolver **referencias** (como pronombres o an√°foras)\n",
    "\n",
    "üîç *Ejemplo*\n",
    "- *‚ÄúMar√≠a lleg√≥ tarde. Estaba cansada.‚Äù*\n",
    "  - Aqu√≠, \"estaba\" se refiere a Mar√≠a.  \n",
    "  - Esta conexi√≥n entre frases es clave para que el texto tenga sentido global.\n",
    "\n",
    "Computacionalmente hablando, esta fase se traduce en tareas como **resoluci√≥n de correferencias**, **segmentaci√≥n de temas**, y **modelado del contexto largo**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3348b6f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e5ca0",
   "metadata": {},
   "source": [
    "<h1>Por el momento vamos a entender las diferentes tareas del an√°lisis l√©xico</h1>\n",
    "Lo dem√°s si est√° medio loco todav√≠a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fb4fd3",
   "metadata": {},
   "source": [
    "# Pipeline NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b285201",
   "metadata": {},
   "source": [
    "Este tipo de datos, como lo son el texto y el audio tiene su propio proceso de tratamiento \\\n",
    "con el fin de poder hacerlo **entendible** para la computadora.\n",
    "\n",
    "Algo as√≠ como que en los num√©ricos tenemos *escalado de datos, normalizaciones, imputaciones, etc...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd8d36c",
   "metadata": {},
   "source": [
    "## 1. Preprocesamiento / Normalizaci√≥n\n",
    "\n",
    "Dentro de esta fase nos encargamos principalmente de obtener aquellas partes \\\n",
    "m√°s representativas del discurso. As√≠ como de la uniformidad de estas.\n",
    "\n",
    "1. Min√∫sculas\n",
    "2. Eliminaci√≥n de puntuaci√≥n, caract√©res especiales\n",
    "3. Eliminaci√≥n de palabras ruido (stopwords)\n",
    "\n",
    "Adem√°s de esto, dentro de esta fase **dividimos el texto en peque√±os conjuntos \\\n",
    "del mismo, de tal forma que al final obtenemos un *_vector no num√©rico_* del texto**\n",
    "\n",
    "- El perro estuvo comiendo unas croquetas con sabor a pescado\n",
    "- [perro, estuvo, comiendo, croquetas, sabor, pescado]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274c6a90",
   "metadata": {},
   "source": [
    "## 2. Vectorizaci√≥n\n",
    "\n",
    "Se busca **una representaci√≥n num√©rica del texto ya procesado en el paso anterior**.\n",
    "\n",
    "**LAS COMPUTADORAS SOLO ENTIENDEN NUM√âROS**\n",
    "\n",
    "1. Bag of words\n",
    "2. TF-IDF\n",
    "3. Word embeddings (Word2Vec, GloVe)\n",
    "4. Embeddings contextuales (BERT, GPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d709351",
   "metadata": {},
   "source": [
    "## 3. Modelado\n",
    "\n",
    "Se aplican algoritmos que aprenden patrones a partir de los vectores obtenidos. \\\n",
    "Estos algoritmos pueden tener diferntes prop√≥stios, como por ejemplo el autocompletado, o solo Q&A\n",
    "\n",
    "1. Clasificadores: SPAM / No SPAM\n",
    "    - Naive Bayes, SVM, Regresi√≥n Log√≠stica\n",
    "2. An√°lisis de Sentimiento\n",
    "    - RNN, LSTM\n",
    "3. Res√∫menes\n",
    "    - Transformers\n",
    "4. Chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae902ca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e247a36",
   "metadata": {},
   "source": [
    "`Texto crudo ‚Üí Preprocesamiento ‚Üí Vectorizaci√≥n ‚Üí Modelado`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b0cf6b",
   "metadata": {},
   "source": [
    "![Text Hierarchy](Text-Hierarchy.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c18700",
   "metadata": {},
   "source": [
    "#### Token\n",
    "\n",
    "Es la **unidad m√≠nima procesable**. Generalmente una palabra, aunque tambi√©n puede ser una subpalabra, s√≠mbolo o signo de puntuaci√≥n, dependiendo del tokenizador.\n",
    "\n",
    "Ejemplo:\n",
    "> Texto: *\"El perro duerme.\"*  \n",
    "‚Üí Tokens: `[\"El\", \"perro\", \"duerme\", \".\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d1226",
   "metadata": {},
   "source": [
    "#### Vocabulario\n",
    "Es el conjunto de **tokens √∫nicos** en un corpus.\n",
    "\n",
    "Ejemplo:\n",
    "> Corpus: `\"Me gustan los perros y los gatos. Los perros ladran.\"`  \n",
    "‚Üí Vocabulario: `[\"Me\", \"gusta\", \"los\", \"perros\", \"y\", \"gatos\", \"ladran\", \".\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85acc8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gatos', 'perros', 'son', 'mascotas', 'preferidas', 'personas', 'gatos', 'hacen', 'miau', 'perros', 'no', 's√©']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "# tratamos a una oraci√≥n como un documento\n",
    "def preprocesar(texto):\n",
    "    stopwords = ['los', 'las', 'el', 'la', 'y', 'de', 'en', 'es', 'una', 'un', 'por', 'para', 'con', 'a', 'est√°n']\n",
    "    texto = texto.lower()\n",
    "    texto = ''.join([c for c in texto if c not in string.punctuation])\n",
    "    tokens = texto.split()\n",
    "    tokens = [t for t in tokens if t not in stopwords]\n",
    "    return tokens\n",
    "\n",
    "texto = \"Los gatos y los perros son las mascotas preferidas de las personas. Los gatos hacen miau y los perros no s√©.\"\n",
    "print(preprocesar(texto))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4845298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sacar el Top N de un corpus, no un documento, un corpus :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0198b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> Corpus = [[documents]] <--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a316e07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El Papa Francisco falleci√≥ el lunes 21 de abril de 2025 a las 07:35 horas en su residencia de la Casa de Santa Marta, en el Vaticano. Ten√≠a 88 a√±os y muri√≥ a causa de un derrame cerebral que le provoc√≥ un coma y un colapso cardiovascular irreversible. Su deceso marc√≥ el fin de un pontificado de 12 a√±os caracterizado por la humildad, la cercan√≠a con los m√°s desfavorecidos y un impulso reformista dentro de la Iglesia Cat√≥lica.\n",
      "\n",
      "\n",
      "Durante sus √∫ltimos d√≠as, Francisco mostr√≥ una notable serenidad. A pesar de su fr√°gil estado de salud, se mantuvo activo y particip√≥ en la misa de Pascua, impartiendo la bendici√≥n Urbi et Orbi desde la Plaza de San Pedro. Su √∫ltima aparici√≥n p√∫blica fue apenas 15 horas antes de su fallecimiento, donde pronunci√≥ palabras de esperanza y paz para el mundo.\n",
      "\n",
      "\n",
      "El anuncio oficial de su muerte fue realizado por el cardenal camarlengo Kevin Farrell, quien destac√≥ la dedicaci√≥n del pont√≠fice al servicio de la Iglesia y su compromiso con los m√°s pobres y marginados. Inmediatamente despu√©s, se activ√≥ el protocolo de la sede vacante, dando inicio al proceso para elegir a su sucesor.\n",
      "\n",
      "\n",
      "El funeral de Francisco se llev√≥ a cabo el 26 de abril en la Plaza de San Pedro, presidido por el Decano del Colegio Cardenalicio, Giovanni Battista Re. Asistieron m√°s de 130 delegaciones internacionales y alrededor de 250,000 fieles. Siguiendo su deseo de humildad, fue enterrado en la Bas√≠lica de Santa Mar√≠a la Mayor, siendo el primer papa desde Le√≥n XIII en no ser sepultado en la Bas√≠lica de San Pedro.\n",
      "\n",
      "\n",
      "La muerte de Francisco gener√≥ una ola de condolencias y homenajes en todo el mundo. L√≠deres pol√≠ticos y religiosos destacaron su papel como defensor de los derechos humanos, promotor de la justicia social y figura clave en el di√°logo interreligioso. Su legado perdurar√° como el de un pont√≠fice que busc√≥ acercar la Iglesia a las realidades contempor√°neas y a los m√°s necesitados.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"text-papa.txt\", \"r\", encoding=\"utf-8\") as archivo:\n",
    "    for linea in archivo:\n",
    "        print(linea.strip())\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466617ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 palabras m√°s frecuentes:\n",
      "parque: 5\n",
      "perro: 2\n",
      "sol: 1\n",
      "brilla: 1\n",
      "ni√±os: 1\n",
      "juegan: 1\n",
      "mar√≠a: 1\n",
      "gusta: 1\n",
      "correr: 1\n",
      "corre: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "STOPWORDS_ES = {\n",
    "    \"el\", \"la\", \"los\", \"las\", \"un\", \"una\", \"unos\", \"unas\", \"de\", \"del\", \"al\",\n",
    "    \"a\", \"en\", \"por\", \"con\", \"y\", \"o\", \"es\", \"que\", \"se\", \"su\", \"muy\", \"tambi√©n\",\n",
    "    \"entre\", \"todas\", \"todos\", \"mientras\", \"para\", \"como\", \"le\"\n",
    "}\n",
    "\n",
    "PUNTUACION = {\n",
    "    '.': '', ',': '', ';': '', ':': '', '!': '', '?': '', '¬°': '', '¬ø': '',\n",
    "    '\"': '', \"'\": '', '(': '', ')': '', '[': '', ']': '', '{': '', '}': '',\n",
    "    '-': '', '_': '', '/': '', '\\\\': ''\n",
    "}\n",
    "\n",
    "def eliminar_puntuacion(texto):\n",
    "    resultado = \"\"\n",
    "    for caracter in texto:\n",
    "        if caracter in PUNTUACION:\n",
    "            resultado += PUNTUACION[caracter]\n",
    "        else:\n",
    "            resultado += caracter\n",
    "    return resultado\n",
    "\n",
    "def leer_archivos(carpeta):\n",
    "    corpus = \"\"\n",
    "    for archivo in os.listdir(carpeta):\n",
    "        if archivo.endswith(\".txt\"):\n",
    "            ruta = os.path.join(carpeta, archivo)\n",
    "            with open(ruta, 'r', encoding='utf-8') as f:\n",
    "                corpus += f.read() + \" \"\n",
    "    return corpus\n",
    "\n",
    "def preprocesar_texto(texto, eliminar_stopwords=True):\n",
    "    texto = texto.lower()\n",
    "    texto = eliminar_puntuacion(texto)\n",
    "    tokens = texto.split() # convertir a array\n",
    "    if eliminar_stopwords:\n",
    "        tokens = [palabra for palabra in tokens if palabra not in STOPWORDS_ES]\n",
    "    return tokens\n",
    "\n",
    "def obtener_top_palabras(tokens, top_n=10):\n",
    "    contador = Counter(tokens)\n",
    "    return contador.most_common(top_n)\n",
    "\n",
    "carpeta = '/Users/ismaelporto/Tukey/NLP/Class 1/files'  \n",
    "top_n = 10\n",
    "\n",
    "texto = leer_archivos(carpeta)\n",
    "tokens = preprocesar_texto(texto, eliminar_stopwords=True)\n",
    "top_palabras = obtener_top_palabras(tokens, top_n)\n",
    "\n",
    "print(f\"Top {top_n} palabras m√°s frecuentes:\")\n",
    "for palabra, frecuencia in top_palabras:\n",
    "    print(f\"{palabra}: {frecuencia}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f5b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
